<!DOCTYPE html>
<html lang="en">
<center>
<div id="container" style="width:1100px" align="left">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Predicting Translation Difficulty on Sentence-Level for MT Systems</title>

    <!-- CSS -->
    <link href="http://mt-class.org/penn/dist/css/bootstrap.min.css" rel="stylesheet">
    <link href="http://mt-class.org/penn/assets/css/mt-class.css" rel="stylesheet">   
    <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <!-- MathJax -->
    <script type="text/javascript"
      src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
  </head>
 <body>   
<h1>Predicting Translation Difficulty on Sentence-level for MT Systems</h1>

<div class="alert alert-info">
Jessy Junyi Li and Kai Hong
</div>

<h2>Problem Statement</h2>

<p>Machine Translation (MT), despite its many recent advances, still remains a hard problem. 
Translations produced by automatic systems suffer from problems such as information reordering, misalignments, mistranslations, etc. 
In this study, we propose to explore the question of how difficult a sentence is to translate automatically. 

Intuitivelly, some sentences are easier to translate, while the others are much more difficult.
Consider the following quote: <i>"Time flies like an arrow; fruit flies like a banana."</i>
The first half of the sentence means that time passes very quickly just as an arrow; while the second half of the sentence means that a "fruit fly" enjoys eating a banana.
This kind of sentence could bring big problem for not only human, but also for MT systems.
</p>

<h2>Datasets</h2>
<p> 
We collect our data from the test set of WMT 2011 (Callison-Burch et al., 2011), WMT 2012 (Callison-Burch et al., 2012) and WMT 2013 (Kepler et al., 2013).
The data from these three years include language pairs of English-German, English-French, English-Spanish and English-Czech in both directions. 
Thus a number of language families have been covered, including Germanic (English and German), Romance (French and Spanish) and Slavic (Czech) languages.
For each year, there are about 3,000 segments in all of the languages. 
We use the data of WMT 2012 and WMT 2013 for training. The data from year 2011 is split into development set and testing set. <br><br>
The data is available here: /project/cis/nlp/data/corpora/wmt_test/ <br> <br>

We employ the average of <i>BLEU</i> scores produced by various MT systems as our main indicator of translation difficulty. Detailed objection function and evaluation will be introduced later. 

<h2>Approach and Evaluation</h2>

<h3>Objective Function and Evaluation</h3>

<p>The plan of this study is to investigate and collect a set of language dependent and independent factors of a sentence that are indicative of translation difficulty. 
One challenge of such an approach is the lack of a reliable sentence-level evaluation metric for translation hypothesis. 
We conjecture that with more systems, the average of automatic scores would provide a partial but feasible solution to this problem.
Here, we regard <i>BLEU</i> scores as our goal of prediction. 
The <b>oracle translation difficulty</b> measure for a sentence is thus the average of BLEU scores of all MT systems, where higher score indicates easier sentence-pairs.

For example, consider we want to translate a sentence <i>e1</i> from English into French. 
We have 3 MT systems, which translate the sentence <i>e1</i> into <i>f1</i>, <i>f2</i> and <i>f3</i>. 
Suppose the <i>BLEU</i> score of the sentences <i>f1</i>, <i>f2</i> and <i>f3</i> are respectively 0.1, 0.2 and 0.15; 
Then the <b>sentence difficulty</b> for sentence <i>e1</i> is 0.15.
Suppose we have another sentence <i>e2</i> with an average <i>BLEU</i> score of 0.5, then the sentence <i>e2</i> is easier than sentence <i>e1</i> in our hypothesis.
The average of <i>BLEU</i> scores have been used in similar ways by Birch et al. (2008) and Koehn et al (2009) where they evaluate langauge-level difficulty; 
as well as Nenkova and Louis (2008) where they average over the <i>ROUGE</i> scores to predict input difficulty for automatic summarization. </p>

<p>To make our computation of the difficulty scores more credible, we only use the systems which are implemented on all 4 language pairs (FR-EN, ES-EN, CZ-EN, GR-EN). 
There are 13 systems satisfying this standard for WMT 2013, 5 systems for WMT 2012 and 4 systems for WMT 2011. </p>

<p>We propose two measures of evaluations as objective functions. 
First, we answer the question whether a sentence A is more difficult than sentence B. 
We compute the ratio of correctly answering this question, which ranges between 0 and 1.
A higher score indicates better prediction.
Secondly, since our model assigns a final score for the sentences, we compute the Spearman Correlation between the scores assigned to the sentences and the oracle scores.
This value ranges between -1 and 1. 
</p>

<h3>Proposed Default System and Baseline System</h3>

<p>Since sentence length is one of the most crucial indicators of translation difficulty for human (Mishra et al., 2013), we regard it as our <i>Default System</i>. 
As for the <i>Baseline System</i>, we propose to compute factors such as syntax complexity, subordinations and the number of noun phrases or verb phrases. </p>
For the final system, we plan to employ a supervised model which includes a set of linguistic features.
We plan to use Support Vector Regression or Liblinear as our models.

<h2>Possible Features and Related Work</h2>
<p>We propose to study this problem from two viewpoints. The first viewpoint relies on language dependent factors.
Intuitively some properties unique to certain languages poses problems for automatic systems.
For example, Chinese and Romanian are well known for their zero anaphora (Zhao and Ng, 2007; Mihaila et al., 2011); 
information expressed as individual words in one language may be morphologically expressed in another (Minkov et al., 2007); 
reorderings often must be explicitly handled (Wang, 2007), and a single word in one language may be decomposed into several in another (Popovi et al., 2006).</p>

<p>On the other hand, some factors might make the sentences difficult to translate, independent of language.
Length, for instance, is a natural indicator for how difficult for a human to translate a sentence (Mishra et al., 2013). 
We ask the question whether it is also the case for automatic systems. 
Other indicators we conjecture include the use of subordinations, structure, amount of re-ordering and complexities of verb phrases and noun phrases, etc.
</p>

<p>A handful of studies have looked into predicting the difficulty of translation on language level, rather than on sentence level. 
There, most of the work investiage the general properties which make those language-pairs difficult to translate.
Birch et al. (2008) show that the amount of reordering, morphological complexity and historical relatedness are important factors for predicting the performance of MT systems.
A further study looked into 462 language pairs (in total 22 languages), where the concept of translation model entropy is introduced to capture the amount of uncertainty involved in choosing candidate translation phrases (Koehn et al., 2009).
</p>

<p>Through this study we hope to characterize difficulties that may lie ahead for MT systems, and we aim at quantitatively estimate such difficulties by developing a set of features for a machine learning framework.
</p>

<h2>References</h2>

<p>Alexandra Birch, Miles Osborne, and Philipp Koehn. 2008. Predicting success in machine translation. <i>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</i>  pages 745–754, Honolulu, Hawaii, October. Association for Computational Linguistics.</p>

<p>Chris Callison-Burch, Philipp Koehn, Christof Monz and Omar Zaidan, 2011. <i>Proceedings of the Six Workshop on Statistical Machine Translation.</i> 

<p>Chris Callison-Burch, Philipp Koehn, Christof Monz, Matt Post, Radu Soricut and Lucia Specia, 2012. <i>Proceedings of the Seventh Workshop on Statistical Machine Translation.</i> 

<p>Ondrej Bojar, Christian Buck, Chris Callison-Burch, Barry Haddow, Philipp Koehn, Christof Monz, Matt Post, Herve Saint-Amand, Radu Soricut and Lucia Specia, 2013. <i>Proceedings of the Eighth Workshop on Statistical Machine Translation.</i> 

<p>Philipp Koehn, Alexandra Birch, and Ralf Steinberger. 2009. 462 machine translation systems for Europe.</p>

<p>Claudiu Mihaila, Iustina Ilisei, and Diana Inkpen. 2011. Zero pronominal anaphora resolution for the romanian language. <i>Research Journal on Computer Science and Computer Engineering with Applications POLIBITS</i>, 42.</p>

<p>Einat Minkov, Kristina Toutanova, and Hisami Suzuki. 2007. Generating complex morphology for machine translation. In <i>Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics</i>, pages 128–135, Prague, Czech Republic, June. Association for Computational Linguistics.</p>

<p>Abhijit Mishra, Pushpak Bhattacharyya, and Michael Carl. 2013. Automatically predicting sentence translation difficulty. In <i>Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</i>, pages 346–351, Sofia, Bulgaria, August. Association for Computational Linguistics.</p>

<p>Ani Nenkova and Annie Louis. 2008. Can you summarize this? identifying correlates of input difficulty for multi-document summarization. In <i>Proceedings of ACL-08: HLT</i>, pages 825–833, Columbus, Ohio, June. Association for Computational Linguistics.</p>

<p>Maja Popovi, Daniel Stein, and Hermann Ney. 2006. Statistical machine translation of german compound words. In Tapio Salakoski, Filip Ginter, Sampo Pyysalo, and Tapio Pahikkala, editors, <i>Advances in Natural Language Processing</i>, volume 4139 of<i> Lecture Notes in Computer Science</i>, pages 616–624. Springer Berlin Heidelberg.</p>

<p>Chao Wang. 2007. Chinese syntactic reordering for statistical machine translation. In <i>Proceedings of EMNLP</i>, pages 737–745.</p>

<p>Shanheng Zhao and Hwee Tou Ng. 2007. Identification and resolution of Chinese zero pronouns: A machine learning approach. In <i>Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)</i>, pages 541– 550.</p>

<br>
</body>
</table>  
</div></center>
</html>
